{
    "lr": 0.001,
    "opt": "adam",
    "noaug": false,
    "noamp": false,
    "wandb": false,
    "mixup": false,
    "net": "mlpmixer_factorized",
    "bs": "512",
    "size": "32",
    "n_epochs": 500,
    "patch": 4,
    "dimhead": 512,
    "log_dir": "logs_CIFAR10_mlpmixer_from",
    "exp_name": "preempt_channel_layer5_mlpmixer_factorized_lr0.001_bs512",
    "resume_path": null,
    "save_freq": 300,
    "depth": 6,
    "preempt": true,
    "r": 40,
    "ff_layer": null,
    "attn_layer": null,
    "deep": false,
    "patch_layer": null,
    "channel_layer": 5,
    "n_gpus": 1,
    "n_params": 1618906
}